<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Underwater - Mini Stem Mixer</title>
    
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- React and ReactDOM -->
    <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    
    <!-- Babel for JSX -->
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef } = React;

        // Icon components
        const Play = () => (
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" 
                stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <polygon points="5 3 19 12 5 21 5 3"/>
            </svg>
        );

        const Square = () => (
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" 
                stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <rect x="3" y="3" width="18" height="18" rx="2" ry="2"/>
            </svg>
        );

        const Volume2 = () => (
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" 
                stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5"/>
                <path d="M15.54 8.46a5 5 0 0 1 0 7.07"/>
                <path d="M19.07 4.93a10 10 0 0 1 0 14.14"/>
            </svg>
        );

        const AlertCircle = () => (
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" 
                stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <circle cx="12" cy="12" r="10"/>
                <line x1="12" y1="8" x2="12" y2="12"/>
                <line x1="12" y1="16" x2="12.01" y2="16"/>
            </svg>
        );

        function AudioSamplePlayer() {
            // Audio context and nodes refs
            const audioContextRef = useRef(null);
            const audioBuffersRef = useRef({});
            const activeSourcesRef = useRef({});

            // State for selected samples and loading status
            const [selectedSamples, setSelectedSamples] = useState({});
            const [needsUserInteraction, setNeedsUserInteraction] = useState(true);
            const [loadingStatus, setLoadingStatus] = useState({
                isLoading: true,
                failedSamples: [],
            });

            // Generate sample file information
            const audioSamples = Array.from({ length: 19 }, (_, i) => ({
                id: `sample-${String(i + 1).padStart(2, '0')}`,
                name: `Sample ${i + 1}`,
                file: `audio/${String(i + 1).padStart(2, '0')}.mp3`
            }));

            // Function to load a single audio file
            const loadAudioFile = async (filename) => {
                try {
                    const response = await fetch(filename);
                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }
                    const arrayBuffer = await response.arrayBuffer();
                    const audioBuffer = await audioContextRef.current.decodeAudioData(arrayBuffer);
                    return audioBuffer;
                } catch (error) {
                    console.error(`Error loading audio file ${filename}:`, error);
                    throw error;
                }
            };

            // Initialize audio context and load samples
            useEffect(() => {
                // Don't initialize audio context automatically
                // Just load saved selections
                const savedSelections = JSON.parse(localStorage.getItem('selectedSamples') || '{}');
                setSelectedSamples(savedSelections);

                return () => {
                    if (audioContextRef.current?.state !== 'closed') {
                        Object.values(activeSourcesRef.current).forEach(sourceData => {
                            if (sourceData && sourceData.sources) {
                                sourceData.sources.forEach(source => {
                                    try {
                                        source.stop();
                                    } catch (e) {
                                        // Ignore errors from already stopped sources
                                    }
                                });
                            }
                        });
                        audioContextRef.current?.close();
                    }
                };
            }, []);

            // Separate function to load samples
            const loadAllSamples = async () => {
                setLoadingStatus({ isLoading: true, failedSamples: [] });
                const failedSamples = [];

                try {
                    await Promise.all(
                        audioSamples.map(async (sample) => {
                            try {
                                audioBuffersRef.current[sample.id] = await loadAudioFile(sample.file);
                            } catch (error) {
                                failedSamples.push(sample.id);
                            }
                        })
                    );
                } catch (error) {
                    console.error('Error loading samples:', error);
                }

                setLoadingStatus({
                    isLoading: false,
                    failedSamples
                });
            };

            // Save selections to localStorage whenever they change
            useEffect(() => {
                localStorage.setItem('selectedSamples', JSON.stringify(selectedSamples));
            }, [selectedSamples]);

            const toggleSample = (sampleId) => {
                if (loadingStatus.failedSamples.includes(sampleId)) {
                    return; // Don't allow playing failed samples
                }

                if (audioContextRef.current?.state === 'suspended') {
                    audioContextRef.current.resume();
                }

                setSelectedSamples(prev => {
                    const newState = {
                        ...prev,
                        [sampleId]: !prev[sampleId]
                    };

                    // Play or stop the sample
                    if (newState[sampleId]) {
                        playSample(sampleId);
                    } else {
                        stopSample(sampleId);
                    }

                    return newState;
                });
            };

            const playSample = (sampleId) => {
                if (activeSourcesRef.current[sampleId]) {
                    stopSample(sampleId);
                }

                const buffer = audioBuffersRef.current[sampleId];
                if (!buffer) return;

                // Create a gain node for this sample
                const gainNode = audioContextRef.current.createGain();
                gainNode.connect(audioContextRef.current.destination);

                // Initialize sample data
                activeSourcesRef.current[sampleId] = {
                    sources: [],
                    gainNode,
                    nextScheduleTime: 0
                };

                const sampleData = activeSourcesRef.current[sampleId];
                const scheduleAheadTime = 0.2; // Schedule 200ms ahead
                const bufferDuration = buffer.duration;
                const scheduleOverlap = 0.01; // 10ms overlap to prevent gaps

                const scheduleNextBuffer = (startTime) => {
                    const source = audioContextRef.current.createBufferSource();
                    source.buffer = buffer;
                    source.connect(sampleData.gainNode);
                    
                    // Start slightly before the end of the previous buffer
                    source.start(startTime - scheduleOverlap);
                    
                    return source;
                };

                const scheduleBuffers = () => {
                    if (!activeSourcesRef.current[sampleId]) return;

                    const currentTime = audioContextRef.current.currentTime;

                    // Initial scheduling
                    if (sampleData.nextScheduleTime === 0) {
                        // Schedule first buffer immediately
                        const source1 = scheduleNextBuffer(currentTime);
                        sampleData.sources.push(source1);
                        sampleData.nextScheduleTime = currentTime + bufferDuration;

                        // Schedule second buffer to overlap with first
                        const source2 = scheduleNextBuffer(sampleData.nextScheduleTime);
                        sampleData.sources.push(source2);
                    }

                    // Schedule more buffers if needed
                    while (sampleData.nextScheduleTime < currentTime + scheduleAheadTime) {
                        const source = scheduleNextBuffer(sampleData.nextScheduleTime);
                        sampleData.sources.push(source);
                        sampleData.nextScheduleTime += bufferDuration - scheduleOverlap;

                        // Clean up old sources
                        sampleData.sources = sampleData.sources.filter(source => {
                            const endTime = source.startTime + bufferDuration;
                            if (endTime < currentTime) {
                                try {
                                    source.disconnect();
                                } catch (e) {
                                    // Ignore errors from already disconnected sources
                                }
                                return false;
                            }
                            return true;
                        });
                    }

                    // Continue scheduling
                    if (activeSourcesRef.current[sampleId]) {
                        requestAnimationFrame(scheduleBuffers);
                    }
                };

                // Start scheduling
                scheduleBuffers();
            };

            const stopSample = (sampleId) => {
                if (activeSourcesRef.current[sampleId]) {
                    const sampleData = activeSourcesRef.current[sampleId];
                    
                    // Stop all scheduled sources
                    sampleData.sources.forEach(({ source }) => {
                        try {
                            source.stop();
                            source.disconnect();
                        } catch (e) {
                            // Ignore errors from already stopped sources
                        }
                    });

                    // Clean up
                    sampleData.gainNode.disconnect();
                    delete activeSourcesRef.current[sampleId];
                }
            };

            // UI interaction check
            if (needsUserInteraction) {
                return (
                    <div className="flex items-center justify-center min-h-screen bg-black">
                        <button 
                            onClick={async () => {
                                // Initialize audio context after user gesture
                                audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
                                await audioContextRef.current.resume();
                                setNeedsUserInteraction(false);
                                
                                // Now load samples and restore state
                                const savedSelections = JSON.parse(localStorage.getItem('selectedSamples') || '{}');
                                setSelectedSamples(savedSelections);
                                
                                loadAllSamples().then(() => {
                                    // Start playing saved selections after samples are loaded
                                    Object.entries(savedSelections).forEach(([sampleId, isSelected]) => {
                                        if (isSelected) {
                                            playSample(sampleId);
                                        }
                                    });
                                });
                            }}
                            className="px-6 py-3 bg-blue-500 text-white rounded-lg hover:bg-blue-600 
                            transition-colors duration-200 flex items-center gap-2"
                        >
                            <Volume2 />
                            Click to Enable Audio
                        </button>
                    </div>
                );
            }

            if (loadingStatus.isLoading) {
                return (
                    <div className="flex items-center justify-center min-h-screen bg-black">
                        <div className="text-lg text-white font-semibold">Loading audio samples...</div>
                    </div>
                );
            }

            return (
                <div className="min-h-screen bg-black p-4 md:p-8">
                    <div className="max-w-4xl mx-auto space-y-8">
                        <header className="mb-8">
                            <h1 className="text-3xl font-bold text-white mb-2">Underwater - Mini Stem Mixer</h1>
                            <p className="text-gray-600">This is a study for an installation in planning that will use multiple vinyl discs with locked grooves to activate an interactive installation that will allow a unique listening experience to be created for each individual participant.</p>
                            {loadingStatus.failedSamples.length > 0 && (
                                <div className="mt-4 p-4 bg-red-50 border border-red-200 rounded-lg">
                                    <p className="text-red-700 flex items-center gap-2">
                                        <AlertCircle />
                                        Failed to load {loadingStatus.failedSamples.length} sample(s)
                                    </p>
                                </div>
                            )}
                        </header>

                        <div className="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-6">
                            {audioSamples.map((sample) => (
                                <button
                                    key={sample.id}
                                    onClick={() => toggleSample(sample.id)}
                                    disabled={loadingStatus.failedSamples.includes(sample.id)}
                                    className={`
                                        p-4 rounded-lg flex items-center justify-between
                                        transition-all duration-200 ease-in-out
                                        ${loadingStatus.failedSamples.includes(sample.id)
                                            ? 'bg-gray-100 text-gray-400 cursor-not-allowed'
                                            : selectedSamples[sample.id]
                                                ? 'bg-blue-500 text-white hover:bg-blue-600'
                                                : 'bg-white text-gray-800 hover:bg-gray-50 border border-gray-200'
                                        }
                                    `}
                                >
                                    <div className="flex items-center gap-3">
                                        {loadingStatus.failedSamples.includes(sample.id) ? (
                                            <AlertCircle />
                                        ) : selectedSamples[sample.id] ? (
                                            <Square />
                                        ) : (
                                            <Play />
                                        )}
                                        <span className="font-medium">{sample.name}</span>
                                    </div>
                                    <Volume2 />
                                </button>
                            ))}
                        </div>

                        <footer className="mt-8 pt-8 border-t border-gray-800">
                            <p className="text-gray-600">Multiple opportunities present themselves; activation with proximity, triggering of playback using MIDI, and so on.</p>
                            <p className="text-gray-600">For example, a series of targets, each representing 1 sample. Playback or muting of each sample is activated when a participant strikes the target with a fist-sized beanbag.</p>
                            <p className="text-gray-600">The music was designed to be played back at high volume, to enhance the experience.</p>
                        </footer>
                    </div>
                </div>
            );
        }

        // Render the application
        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<AudioSamplePlayer />);
    </script>
</body>
</html>